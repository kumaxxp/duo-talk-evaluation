# 検証軸2b: プロンプト構造比較実験 (Gemma2 27B)
# レイヤリング vs シンプル vs SillyTavern（Ollama）

experiment:
  id: "exp_prompt_comparison_gemma2_005"
  name: "プロンプト構造比較: Layered vs Simple vs SillyTavern (Gemma2 27B via Ollama)"
  description: |
    Gemma2 27B (Ollama)でプロンプト構造のみを変更し、
    character_consistency/naturalnessへの影響を検証する。

    Gemma3 12Bでの同一実験と比較することで、
    LLMとプロンプト構造の交互作用を確認。

base_config:
  llm_backend: "ollama"
  llm_model: "gemma2-27b"
  ollama_model: "gemma2-swallow-27b"
  rag_enabled: false          # RAG無効（変数隔離）
  director_enabled: false     # Director無効（変数隔離）
  few_shot_count: 3
  scenarios:
    - casual_greeting
    - emotional_support
    - topic_exploration

variations:
  - name: "layered_gemma2"
    llm_backend: "ollama"
    llm_model: "gemma2-27b"
    ollama_model: "gemma2-swallow-27b"
    prompt_structure: "layered"
    # duo-talk方式: XML階層構造

  - name: "simple_gemma2"
    llm_backend: "ollama"
    llm_model: "gemma2-27b"
    ollama_model: "gemma2-swallow-27b"
    prompt_structure: "simple"
    # duo-talk-simple方式: フラット構造 + 制約ルール

  - name: "sillytavern_gemma2"
    llm_backend: "ollama"
    llm_model: "gemma2-27b"
    ollama_model: "gemma2-swallow-27b"
    prompt_structure: "sillytavern"
    # SillyTavern方式: Character Card V2準拠

metrics:
  - naturalness
  - character_consistency
  - concreteness
  - relationship_quality
  - topic_novelty

scenario_definitions:
  casual_greeting:
    prompt: "おはよう、二人とも"
    turns: 5
    evaluation_focus:
      - character_consistency
      - naturalness

  emotional_support:
    prompt: "最近疲れてるんだ..."
    turns: 6
    evaluation_focus:
      - relationship_quality
      - naturalness

  topic_exploration:
    prompt: "最近のAI技術について話して"
    turns: 8
    evaluation_focus:
      - topic_novelty
      - concreteness
