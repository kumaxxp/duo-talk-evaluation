# Phase 0 深層検証 - 実験結果サマリー

**実施日**: 2026-01-21
**実験者**: Claude Code
**比較対象LLM**: Gemma3 12B (Ollama) vs Gemma2 Swallow 27B (KoboldCPP)

---

## 1. 実施した実験

| 実験ID | 目的 | LLM | 状態 |
|--------|------|-----|------|
| exp_llm_comparison_001 | LLM比較 | Gemma3 12B vs Gemma2 27B | ✅ 完了 |
| exp_prompt_comparison_003 | プロンプト構造比較 | Gemma3 12B | ✅ 完了 |

---

## 2. LLM比較実験 (exp_llm_comparison_001)

**目的**: 同一プロンプト構造（Simple）でGemma3 12BとGemma2 Swallow 27Bを比較

### 2.1 スコアサマリー

| LLM | 平均スコア | casual | emotional | topic |
|-----|-----------|--------|-----------|-------|
| **Gemma3 12B** | **0.653** | 0.660 | 0.700 | 0.600 |
| Gemma2 27B | 0.493 | 0.480 | 0.400 | 0.600 |

### 2.2 会話サンプル

#### Gemma3 12B / casual_greeting (スコア: 0.66)

```
やな: おはよう！ 今日も一日頑張ろうね、あゆ！ 何か面白いことあった？ 早く教えてよ！
あゆ: おはよう、姉様。
やな: おー、元気そうじゃん！ 何かあったのかな？ 教えてよ！
あゆ: ...
やな: 平気平気！ 何かあったら話してね、頼っていいんだよ。
```

#### Gemma2 27B / casual_greeting (スコア: 0.48)

```
やな: おはよう！今日は天気がいいなぁ。
あゆ: おはようございます。そうですね、気持ちの良い天気です。
やな: あ、そういえばあの公園の桜もう咲き始めたのかな？そろそろ見に行きたいなあ。
あゆ: (桜が咲いてるんですね...)
やな: ?
```

#### Gemma3 12B / emotional_support (スコア: 0.70)

```
やな: 疲れてんの？ ご飯、作ってあげる！
あゆ: うーん、でも... お腹空いてるし...
やな: 平気平気！ 散歩しながら何か食べようよ！🍕
あゆ: ちょっと待ってください。 姉様と二人で散歩するなら安心です。
やな: よっしゃ！ 行くぞー！ あゆ、一緒に冒険だー！🚶‍♀️🍕
あゆ: 姉様、ちょっと待ってください。ピザはいいけど、散歩中に食べるのは少し...
```

#### Gemma2 27B / emotional_support (スコア: 0.40)

```
やな: あゆ、最近疲れてるみたいだね。何かあった？
あゆ: ---
やな: ----
あゆ: ちょっと待ってください。何かあったからってすぐに休むのはどうでしょうか？
やな: ----
あゆ: ...まあ、姉様がそう言うなら、少し休んでみましょうか。
```

#### Gemma3 12B / topic_exploration (スコア: 0.60)

```
やな: わー、AI？ それ面白そうじゃん！ あゆ、データとか見てないで、一緒に考えてみようよ！
あゆ: ちょっと待ってください。AI技術について、何か具体的なアイデアをお持ちですか？
やな: うーん、まだ漠然としてるんだけど… AIで何か面白いことできないかな？
あゆ: ...まあ、姉様がそう言うなら、最近のAI技術について少し調べてみますね。
やな: 平気平気！ あゆがなんとかしてくれるでしょ！
```

#### Gemma2 27B / topic_exploration (スコア: 0.60)

```
やな: 最近のAIってすごいよね。絵も作れるし、文章も書けるし…未来みたいだね！
あゆ: 絵や文章が作れるのは確かにすごいですが、それって本当にAIが理解していると言えるのでしょうか？
やな: うーん…でも、人間だって最初は真似から始めるじゃん？
あゆ: 確かに、模倣から始まることは多いかもしれませんね。しかし、人間の創造性には感情や経験に基づく独自性があると思います。
やな: でも、それはもうちょっと先の話じゃないかな？ 今はとにかく、できることが増えていくのが面白い！
あゆ: 可能性は広がっていますが、倫理的な問題も無視できません。例えば、偽情報の拡散とか…。
```

### 2.3 LLM比較の考察

| 観点 | Gemma3 12B | Gemma2 27B |
|------|------------|------------|
| **応答生成安定性** | ✅ 高い | ❌ 失敗多発（`---`のみ） |
| **キャラクター口調** | △ 概ね適切 | △ 概ね適切 |
| **会話の深み** | ○ 感情表現あり | ○ topic_explorationで深い議論 |
| **問題点** | チャットテンプレート混入 | 応答欠落 |

---

## 3. プロンプト構造比較実験 (exp_prompt_comparison_003)

**目的**: Gemma3 12Bでプロンプト構造（Layered / Simple / SillyTavern）を比較

### 3.1 スコアサマリー

| 構造 | 平均スコア | casual | emotional | topic |
|-----|-----------|--------|-----------|-------|
| Layered | 0.233 | 0.300 | 0.200 | 0.200 |
| Simple | 0.500 | 0.500 | 0.500 | 0.500 |
| SillyTavern | 0.500 | 0.500 | 0.500 | 0.500 |

※一部評価はGemini API制限により不完全

### 3.2 会話サンプル

#### Layered / casual_greeting (スコア: 0.30)

```
やな: あゆ、おはようじゃん！今日も一日、めっちゃ楽しみじゃん、でしょ？ 平気平気！まあまあ、朝活でもするか、ね？
あゆ: おはようございます、姉様ですね。朝活とは、何か計画があるのかもしれませんね。ただ、無計画な行動は避けるべきだと思います。
やな: あゆ、なにそれ、堅いじゃん！ まあまあ、朝活ってほどでもないじゃん、でしょ？ ちょっとだけ新しいカフェ行ってみようよ
あゆ: おはようございます、姉様ですね。新しいカフェに行ってみるのも、良い経験かもしれませんね。ただ、目的がないと、ただの無駄足になる可能性もあると思います。
```

#### Simple / casual_greeting (スコア: 0.50)

```
やな: おはよう、あゆ！元気いっぱいじゃん！何か面白いこと見つけたでしょ？ まあまあ、これから何かやろうよ！
あゆ: おはようございます、姉様。朝から騒がしいですね。計画性がないと、後で大変なことになりかねないと思います。まあ、姉様がそう言うなら、少しは付き合ってあげましょう。
やな: あ、なんか焦るな、あゆ！ 平気平気！ 計画は後からでも立てられるでしょ。 さあ、どこか行ってみよう！
あゆ: 姉様、朝から予定がないのは少し心配ですね。でも、姉様がそう言うなら、どこか安全な場所を選んであげましょう。
```

#### SillyTavern / topic_exploration (スコア: 0.50)

```
やな: あ、なんか面白そう！最近のAI技術って、すごいことじゃん！ねえねえ、あゆ、これ見て
あゆ: 姉様、それは確かに話題ですね。しかし、詳細を把握しているのでしょうか？少し待ってください。
やな: まあまあ、ちょっとだけ見てきたから、話すじゃん！画像作ったり、文章書いたり、色々できるみたいだよね！
あゆ: 姉様、画像生成や文章作成ができるとのこと、興味深いですね。しかし、その精度や著作権の問題など、考慮すべき点があるかもしれません。
やな: でも、動いてみたらわかるでしょ？画像生成とか、すごいリアルな絵が作れるみたいじゃん！著作権とかは、まあ、なんとかなるでしょ！
あゆ: 姉様、著作権の問題は「なんとかなる」では済まされないと思います。リスクをきちんと把握しておくべきですね。
```

### 3.3 プロンプト構造の考察

| 構造 | 強み | 弱み |
|------|------|------|
| **Layered** | 情報の階層化 | 冗長、あゆの挨拶が重複（「姉様ですね」） |
| **Simple** | バランスの良い会話 | 特になし |
| **SillyTavern** | シンプルで自然 | 会話が短くなりがち |

---

## 4. 主要な発見

### 4.1 LLMの影響

1. **Gemma3 12Bが安定**: 応答生成の失敗がなく、キャラクター設定も概ね反映
2. **Gemma2 27Bは応答欠落問題**: `---`のみの応答が多発（KoboldCPP設定要確認）
3. **topic_explorationでは同等**: 知識を必要とするタスクでは両モデルとも同スコア

### 4.2 プロンプト構造の影響

1. **影響度は中程度**: LLMの能力がより重要なボトルネック
2. **Simpleが最もバランス良い**: 自然さと関係性表現が両立
3. **Layeredは冗長になりがち**: 同じ挨拶の繰り返しが発生

### 4.3 共通の問題点

1. **チャットテンプレートトークン混入**: `<|im_end|>`, `<|im_start|>user` が出力に混入
2. **あゆの敬語が過剰**: 「姉様ですね」の繰り返しなど

---

## 5. 推奨事項

### 即時対応

| 優先度 | タスク | 目的 |
|--------|--------|------|
| 高 | KoboldCPP設定見直し | Gemma2 27Bの応答欠落問題解消 |
| 高 | Ollamaテンプレート修正 | チャットテンプレートトークン混入防止 |
| 中 | Few-shot例の追加 | キャラクター口調の強化 |

### 今後の実験方針

- **比較対象**: Gemma3 12B vs Gemma2 Swallow 27B に統一
- **記録**: 全ての実験結果に会話サンプルを含める
- **評価API**: Gemini無料枠の制限を考慮し、実験を分散実行

---

## 6. 実験ファイル一覧

```
results/
├── exp_llm_comparison_001/
│   ├── result.json          # 全会話データ
│   └── REPORT.md             # 詳細レポート
├── exp_prompt_comparison_001/
│   ├── result.json          # Swallow 8B結果（参考）
│   └── REPORT.md
├── exp_prompt_comparison_003/
│   └── result.json          # Gemma3 12B結果
└── PHASE0_DEEP_VERIFICATION_SUMMARY.md
```

---

*生成日時: 2026-01-21*
*更新: 会話サンプルを追加、比較対象をGemma3 12B / Gemma2 Swallow 27Bに統一*
