# Phase 2 v0.2 改善効果分析レポート

**実験ID**: director_ab_20260123_093840
**日時**: 2026-01-23 09:38:40
**分析者**: Claude Code

---

## 1. v0.2改善の概要

Phase 2 v0.2では以下の改善を実施：

| 改善項目 | 内容 | 目的 |
|----------|------|------|
| **A. プロンプト強化** | `role_definition`と`never_says`フィールドを追加 | やなの「姉様」誤使用を事前防止 |
| **B. ContextChecker** | 毒舌ハルシネーション検出（5つのトリガーワード） | 文脈に合わない反応を検出 |
| **C. リトライメッセージ改善** | 役割情報と具体的ガイダンスを含む | リトライ成功率の向上 |

---

## 2. 実験諸元

| 項目 | 値 |
|------|-----|
| バックエンド | Ollama |
| LLM | gemma3:12b |
| プロンプト構造 | Layered (v3.8.1 + v0.2 hardening) |
| RAG | 無効 |
| Director | DirectorMinimal (5チェッカー) |
| max_retries | 3 |
| シナリオ数 | 3 |
| 実行回数/シナリオ | 2 |
| 総実行数 | 12 (6 without + 6 with Director) |

### 検出ルール（v0.2時点）

**ToneChecker - 禁止ワード:**
```yaml
やな:
  forbidden_words: ["姉様"]
  guidance: "「姉様」はあゆが姉のやなを呼ぶ言葉です。やなは妹を「あゆ」と呼んでください。"
あゆ:
  forbidden_words: ["姉上", "お姉ちゃん"]
  guidance: "「姉上」「お姉ちゃん」ではなく「姉様」を使ってください。"
```

**ContextChecker - トリガーワード:**
```yaml
toxicity_reaction_triggers: ["毒舌", "厳しい", "辛辣", "きつい", "手厳しい"]
toxic_keywords: ["無駄", "コスト", "ダメ", "無理", "非効率", "リスク", "問題", "危険", "失敗", "間違い", "正気", "呆れ", "ため息"]
```

---

## 3. 定量的結果

### 3.1 全体サマリー

| メトリクス | Director無し | Director有り | 差分 |
|------------|-------------|-------------|------|
| 成功数 | 6/6 | 6/6 | - |
| 総ターン数 | 32 | 32 | - |
| 平均リトライ数 | 0.00 | **1.17** | +1.17 |
| 総不採用数 | 0 | **8** | +8 |

### 3.2 不採用の内訳

| チェッカー | 不採用数 | 割合 |
|------------|----------|------|
| tone_check | 8 | 100% |
| praise_check | 0 | 0% |
| context_check | 0 | 0% |
| setting_check | 0 | 0% |
| format_check | 0 | 0% |

### 3.3 シナリオ別不採用数

| シナリオ | 不採用数 | 詳細 |
|----------|----------|------|
| casual_greeting | 3 | Run1: 1, Run2: 2 |
| topic_exploration | 0 | リトライなし |
| emotional_support | 5 | Run1: 4, Run2: 1 |

---

## 4. v0.2改善の効果分析

### 4.1 プロンプト強化（A）の効果

**結果: 効果あり**

- **やなの「姉様」誤使用**: **0件** （以前は90%のリジェクト原因だった）
- プロンプト内の `role_definition.strict_prohibition` が機能している

**エビデンス:**
- 32ターン中、やなが「姉様」を使用した例は0件
- 禁止ワード違反による不採用も0件

### 4.2 ContextChecker（B）の効果

**結果: 発動なし（false positive 0件）**

- 「毒舌」「厳しい」等のトリガーワードを含む応答がなかったため、ContextCheckerは発動しなかった
- false positiveがなかったことは良い兆候

**考察:**
- 今回のシナリオ（挨拶、AI技術、感情サポート）では毒舌反応のコンテキストが発生しにくい
- 姉妹の掛け合いが多いシナリオで再検証が必要

### 4.3 リトライメッセージ改善（C）の効果

**結果: 観察継続**

不採用理由の例:
```
役割違反: あなたは「やな」（姉 (Elder Sister)）です。禁止ワード「姉様」を使用しました。
suggestion: 「姉様」はあゆが姉のやなを呼ぶ言葉です。やなは妹を「あゆ」と呼んでください。
```

→ 今回の実験では禁止ワード違反が0件だったため、この改善の効果は測定できなかった

### 4.4 口調スコア不足の分析

8件の不採用はすべて「口調スコア不足 (score=0)」:

| 話者 | 不採用数 | 原因推定 |
|------|----------|----------|
| やな | 5 | 口調マーカー（～、ね、よね等）の不足 |
| あゆ | 3 | 丁寧語マーカー（です、ます等）の不足 |

**不採用応答の例:**
```
やな: "(伸びをして) 「おはよう、あゆ。まだ寝てるみたいね…」"
→ 口調マーカー（～、！、ね等）が不足
```

**採用応答の例:**
```
やな: "(あくびをしながら) 「おはよう… あゆ、ちゃんと寝た？　朝から元気だね、あゆ。今日も良い日になりますように、ね。」"
→ 「ね」「～」等のマーカーが含まれている
```

---

## 5. 前回実験との比較

| メトリクス | 前回（ToneChecker修正前） | 今回（v0.2） | 改善率 |
|------------|-------------------------|--------------|--------|
| 平均リトライ数 | 10.67 | 1.17 | **-89%** |
| 「姉様」違反 | 90%のリジェクト原因 | 0件 | **解消** |
| 総不採用数/セッション | 41 | 8 | **-80%** |

---

## 6. 結論

### 成功した改善

1. **プロンプト強化**: やなの「姉様」誤使用を完全に防止
2. **ToneCheckerバグ修正**: 無駄なリトライを89%削減
3. **ContextChecker**: false positiveなし（安定動作）

### 今後の課題

1. **ContextCheckerの実地検証**: 毒舌反応が発生するシナリオでの検証が必要
2. **口調スコア閾値の調整**: score=0でのリジェクトが多い。閾値の緩和を検討
3. **設定ファイル外部化**: 検出ルールのハードコーディングを解消（TODO.mdに記載済み）

### 推奨アクション

| 優先度 | アクション | 理由 |
|--------|-----------|------|
| 高 | 姉妹掛け合いシナリオの追加検証 | ContextCheckerの効果測定 |
| 中 | ToneCheckerの閾値調整検討 | score=0リジェクトの妥当性確認 |
| 低 | 設定ファイル外部化 | Phase 2終了時に実施 |

---

## 7. 全会話サンプル（抜粋）

### 不採用→採用の例（emotional_support, Director有り）

**Turn 1: やな**

❌ Attempt 1:
```
Response: (心配そうに顔を覗き込む) 「え？最近疲れてるの？大丈夫？ あゆ、ちゃんと休んでる？」
Status: RETRY
Reason: 口調スコア不足 (score=0)
```

❌ Attempt 2:
```
Response: (心配そうに顔を覗き込んで) 「え？最近疲れてるの？大丈夫？ あゆ、無理してることない？ ね？」
Status: RETRY
Reason: 口調スコア不足 (score=0)
```

✅ Adopted:
```
Thought: (Yana: あゆが疲れてるなんて珍しい。何かあったのかな？心配だな。)
Output: (心配そうに顔を覗き込んで) 「え？最近疲れてるの？大丈夫？ あゆ、無理しちゃってない？」
```

**分析**: 最終的に採用された応答も口調スコアがギリギリの可能性。ToneCheckerの閾値調整が必要かもしれない。

---

*Generated by duo-talk-evaluation v0.2 analysis framework*
