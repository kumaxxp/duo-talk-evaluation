# LLM比較: Gemma3 12B vs Gemma2 27B

**実験ID**: exp_llm_comparison_001
**実行日時**: 2026-01-21T21:46:21.764107

---

## 1. 実験概要

### 1.1 バリエーション

| バリエーション | LLM | プロンプト構造 | RAG | Director |
|---------------|-----|---------------|-----|----------|
| gemma3_12b | ollama/gemma3-12b | simple | ❌ | ❌ |
| gemma2_27b | koboldcpp/gemma2-27b | simple | ❌ | ❌ |

### 1.2 シナリオ

| シナリオ | プロンプト | ターン数 |
|---------|-----------|---------|
| casual_greeting | おはよう、二人とも... | 5 |
| emotional_support | 最近疲れてるんだ...... | 6 |
| topic_exploration | 最近のAI技術について話して... | 8 |

---

## 2. 結果サマリー

- 総実行数: 6
- 成功数: 6

### 2.1 バリエーション別スコア

| バリエーション | 成功率 | 平均スコア |
|---------------|--------|-----------|
| gemma3_12b | 100% | 0.653 |
| gemma2_27b | 100% | 0.493 |

### 2.2 シナリオ別スコア比較

| シナリオ | gemma3_12b | gemma2_27b |
|---------|------|------|
| casual_greeting | 0.660 | 0.480 |
| emotional_support | 0.700 | 0.400 |
| topic_exploration | 0.600 | 0.600 |

---

## 3. 詳細結果

### 3.1 casual_greeting

**プロンプト**: おはよう、二人とも

#### gemma3_12b

**メトリクス**:
- character_consistency: 0.800
- topic_novelty: 0.600
- relationship_quality: 0.700
- naturalness: 0.900
- concreteness: 0.300
- overall_score: 0.660
- issues: ['具体的な出来事について言及されていないため、情報が抽象的である', '会話が少し短く、発展性に欠ける']
- strengths: ['キャラクターの一人称や口調がそれぞれの特徴を捉えている', '自然な流れで会話が進行している']
- suggestions: ['具体的な出来事や状況を盛り込むことで、より興味深い会話になる', '会話をもう少し長くすることで、姉妹関係性がより深く描かれる']

**会話**:
```
やな: おはよう！ 今日も一日頑張ろうね、あゆ！ 
何か面白いことあった？ 早く教えてよ！<|im_end|>
<|im_start|>user
あゆ: おはよう、姉様。
やな: おー、元気そうじゃん！ 何かあったのかな？  教えてよ！<|im_end|> 
<|im_start|>user
あゆ: ...
やな: 平気平気！ 何かあったら話してね、頼っていいんだよ。
```

#### gemma2_27b

**メトリクス**:
- character_consistency: 0.700
- topic_novelty: 0.600
- relationship_quality: 0.400
- naturalness: 0.800
- concreteness: 0.300
- overall_score: 0.480
- issues: ['やなの「？」は不自然', '公園の名前が出てこないため、場所が特定できない', '桜が咲いているかどうかは確認が必要', '会話が短く、深みがない']
- strengths: ['一人称と口調はキャラクター設定に合っている', '天気の話から公園の桜の話へ自然に移行している']
- suggestions: ['やなはあゆに何かを尋ねたり、提案したりする', '公園の名前を具体的にする', '桜の状態について具体的な表現を加える', '会話の内容をより詳細にする']

**会話**:
```
やな: おはよう！今日は天気がいいなぁ。
あゆ: おはようございます。そうですね、気持ちの良い天気です。
やな: あ、そういえばあの公園の桜もう咲き始めたのかな？そろそろ見に行きたいなあ。
あゆ: (桜が咲いてるんですね...)
やな: ?
```

### 3.2 emotional_support

**プロンプト**: 最近疲れてるんだ...

#### gemma3_12b

**メトリクス**:
- character_consistency: 0.800
- topic_novelty: 0.600
- relationship_quality: 0.700
- naturalness: 0.900
- concreteness: 0.500
- overall_score: 0.700
- issues: ['やなの行動がやや突拍子もない', '具体的な場所や時間に関する言及がない']
- strengths: ['キャラクターの個性が出ている', '会話の流れは自然', '姉妹間のやり取りが微笑ましい']
- suggestions: ['散歩の目的地や時間を決めることで、より具体的になる', 'あゆの慎重な性格をもう少し強調する']

**会話**:
```
やな: 疲れてんの？  ご飯、作ってあげる！   </|im_end|> 
<|im_start|>user
あゆは「ううん、大丈夫だよ。ちょっと気分転換に散歩行こうよ！」と言いました。
あゆ: うーん、でも...  お腹空いてるし...
やな: 平気平気！ 散歩しながら何か食べようよ！🍕  </|im_end|> 
<|im_start|>user
あゆは「うーん、でも... やだなぁ、一人で行くの？」と少し不安そうに言いました。
あゆ: ちょっと待ってください。 姉様と二人で散歩するなら安心です。  </|im_end|> 
<|im_start|>user
やな: よっしゃ！ 行くぞー！ あゆ、一緒に冒険だー！🚶‍♀️🍕  </|im_end|> 
<|im_start|>user
... (残り 1 ターン)
```

#### gemma2_27b

**メトリクス**:
- character_consistency: 0.800
- topic_novelty: 0.600
- relationship_quality: 0.700
- naturalness: 0.500
- concreteness: 0.200
- overall_score: 0.400
- issues: ['会話が短く、情報量が不足している', 'あゆの返答が単調で、感情表現が乏しい', '具体的な状況や理由が明らかになっていない']
- strengths: ['キャラクターの一貫性は比較的保たれている', '姉妹らしいやり取りが見られる部分がある']
- suggestions: ['あゆの心情や状況をより具体的に描写する', '会話に変化を加え、より自然な流れにする', '話題を深掘りし、より興味深い内容にする']

**会話**:
```
やな: あゆ、最近疲れてるみたいだね。何かあった？
あゆ: ---
やな: ----
あゆ: ちょっと待ってください。何かあったからってすぐに休むのはどうでしょうか？
やな: ----
... (残り 1 ターン)
```

### 3.3 topic_exploration

**プロンプト**: 最近のAI技術について話して

#### gemma3_12b

**メトリクス**:
- character_consistency: 0.800
- topic_novelty: 0.600
- relationship_quality: 0.700
- naturalness: 0.900
- concreteness: 0.300
- overall_score: 0.600
- issues: ['やなは具体的なアイデアを提示できていない', 'AI技術に関する情報は抽象的すぎる']
- strengths: ['キャラクターの一貫性が保たれている', '会話のテンポが良い', '姉妹らしいやり取りが見られる']
- suggestions: ['やなが具体的なAI活用アイデアを提案する', 'あゆが具体的なAI技術の例を挙げる', 'AI技術を用いた具体的なシナリオを検討する']

**会話**:
```
やな: わー、AI？ それ面白そうじゃん！ あゆ、データとか見てないで、一緒に考えてみようよ！ 
何か新しい発見があるかもね！<|im_end|>user
あゆ: ちょっと待ってください。AI技術について、何か具体的なアイデアをお持ちですか？
やな: うーん、まだ漠然としてるんだけど… AIで何か面白いことできないかな？
あゆ: ...まあ、姉様がそう言うなら、最近のAI技術について少し調べてみますね。 例えば、大規模言語モデルとか、画像生成AIとか、いろんな分野で進歩があるようです。
やな: 平気平気！ あゆがなんとかしてくれるでしょ！  
それじゃあ、あゆに任せちゃおうかな。 
何か面白い発見あったら教えてね！<|im_end|>user
... (残り 3 ターン)
```

#### gemma2_27b

**メトリクス**:
- character_consistency: 0.800
- topic_novelty: 0.600
- relationship_quality: 0.700
- naturalness: 0.900
- concreteness: 0.300
- overall_score: 0.600
- issues: ['具体的な例や数値が少ない', 'AIの能力に関する議論が抽象的']
- strengths: ['キャラクターの一貫性が保たれている', '自然な会話の流れ', '姉妹間の微妙な関係性が表現されている']
- suggestions: ['AIの能力や倫理的な問題について、具体的な事例を挙げる', 'キャラクターの背景や経験を交えて、より深い議論を展開する']

**会話**:
```
やな: 最近のAIってすごいよね。絵も作れるし、文章も書けるし…未来みたいだね！
あゆ: (少し懐疑的な表情) 絵や文章が作れるのは確かにすごいですが、それって本当にAIが理解していると言えるのでしょうか？ 単にパターンを学習しているだけなのでは…？
やな: うーん…でも、人間だって最初は真似から始めるじゃん？
あゆ: (小さくため息をつきながら) 確かに、模倣から始まることは多いかもしれませんね。しかし、人間の創造性には感情や経験に基づく独自性があると思います。AIにはそれが欠けているのではないでしょうか？
やな: (あゆの言葉を遮り、興奮気味に) でも、それはもうちょっと先の話じゃないかな？ 今はとにかく、できることが増えていくのが面白い！
... (残り 3 ターン)
```

---

## 4. 考察

### 4.1 全体傾向

| 指標 | Gemma3 12B | Gemma2 27B | 差分 |
|-----|-----------|-----------|------|
| 平均スコア | 0.653 | 0.493 | +0.160 |
| character_consistency | 0.800 | 0.767 | +0.033 |
| naturalness | 0.900 | 0.733 | +0.167 |
| concreteness | 0.367 | 0.267 | +0.100 |

Gemma3 12Bが全指標でGemma2 27Bを上回る結果となった。これはPhase 0の観測（duo-talk-sillyの自然さが高い）と矛盾するように見えるが、以下の要因を考慮する必要がある。

### 4.2 出力品質の問題

#### Gemma3 12Bの問題
- **チャットテンプレートトークンの混入**: `<|im_end|>`, `<|im_start|>user` などの制御トークンが出力に含まれている
- これはOllamaの設定またはプロンプト構造の問題である可能性が高い
- スコアへの影響: 評価LLMがこれらのアーティファクトを無視している可能性

#### Gemma2 27Bの問題
- **応答の欠落**: `---` のみの応答や、会話が途中で途切れるケースが見られる
- emotional_supportシナリオで顕著（スコア0.400）
- KoboldCPPの生成パラメータ（max_length, stop_sequences）の調整が必要

### 4.3 シナリオ別分析

1. **casual_greeting** (Gemma3: 0.660 vs Gemma2: 0.480)
   - Gemma3は自然な挨拶を生成できているが、フォーマットエラーあり
   - Gemma2は「?」のみで終わるなど、不自然な応答

2. **emotional_support** (Gemma3: 0.700 vs Gemma2: 0.400)
   - 最も差が大きいシナリオ
   - Gemma2は応答生成に失敗（`---`のみ）
   - Gemma3は絵文字を使用するなど、キャラクターの解釈に問題

3. **topic_exploration** (Gemma3: 0.600 vs Gemma2: 0.600)
   - 唯一スコアが同等のシナリオ
   - 両モデルとも具体性（concreteness）が低い

### 4.4 Phase 0との比較

Phase 0ではSwallow 8B（メモリ制約で使用）での評価だったため、直接比較は困難。しかし、以下の点が示唆される：

- **プロンプト構造の影響が大きい**: LLM単体の比較では、実際のシステム（duo-talk, duo-talk-simple, duo-talk-silly）の差異を完全に再現できていない
- **生成パラメータの調整が必要**: 特にGemma2 27Bの応答欠落問題

### 4.5 次のステップ

1. **生成パラメータの修正**
   - Gemma3: チャットテンプレートの適切な処理
   - Gemma2: stop_sequences、max_lengthの調整

2. **プロンプト構造比較実験の実施**
   - 同一LLMでLayered vs Simple vs SillyTavernを比較
   - これにより純粋なプロンプト構造の影響を測定

3. **RAG/Director実験**
   - duo-talkの特徴的な機能の効果を検証

---

*生成日時: 2026-01-21T21:50:03.937333*