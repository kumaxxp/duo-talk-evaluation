# Phase 2 v0.4 改善効果分析レポート

**実験ID**: director_ab_20260123_120140
**日時**: 2026-01-23 12:01:40
**分析者**: Claude Code

---

## 1. v0.4改善の概要

Phase 2 v0.4では**ThoughtChecker**を新規追加：

| 改善項目 | 内容 | 目的 |
|----------|------|------|
| **A. ThoughtChecker追加** | Thought/Output形式の検証 | 思考プロセスの可視化を強制 |
| **B. 空Thought検出** | "Thought: (" のみの応答を検出 | 意味のある思考を促す |
| **C. 欠落検出** | "Thought:" マーカー無しを検出 | フォーマット遵守 |

### DirectorMinimal チェッカー構成（v0.4）

| # | チェッカー | 内容 |
|---|------------|------|
| 1 | **thought_check** | Thought/Output形式検証 **← 新規** |
| 2 | tone_check | 口調マーカー（Negative Policing v2.1） |
| 3 | praise_check | 過剰な褒め言葉検出 |
| 4 | context_check | コンテキスト一貫性 |
| 5 | setting_check | 世界設定整合性 |
| 6 | format_check | 応答長検証 |

---

## 2. 実験諸元

| 項目 | 値 |
|------|-----|
| バックエンド | Ollama |
| LLM | gemma3:12b |
| プロンプト構造 | Layered (v3.8.1) |
| RAG | 無効 |
| Director | DirectorMinimal (6チェッカー) |
| max_retries | 3 |
| シナリオ数 | 3 |
| 実行回数/シナリオ | 2 |
| 総実行数 | 12 (6 without + 6 with Director) |

---

## 3. 定量的結果

### 3.1 全体サマリー

| メトリクス | Director無し | Director有り | 差分 |
|------------|-------------|-------------|------|
| 成功数 | 6/6 | 6/6 | - |
| 平均リトライ数 | 0.00 | **10.67** | +10.67 |
| 総不採用数 | 0 | **96** | +96 |

### 3.2 不採用の内訳

| チェッカー | 不採用数 | 割合 | 違反タイプ |
|------------|----------|------|------------|
| **thought_check** | **96** | **100%** | Thought欠落 |
| tone_check | 0 | 0% | - |
| praise_check | 0 | 0% | - |
| context_check | 0 | 0% | - |
| setting_check | 0 | 0% | - |
| format_check | 0 | 0% | - |

### 3.3 評価スコア比較

| メトリクス | Director無し | Director有り |
|------------|-------------|-------------|
| 平均overall_score | 0.71 | 0.71 |
| casual_greeting | 0.58 | 0.63 |
| topic_exploration | 0.78 | 0.82 |
| emotional_support | 0.78 | 0.69 |

---

## 4. v0.3 → v0.4 比較分析

### 4.1 リトライ数の変化

| メトリクス | v0.3 | v0.4 | 変化 |
|------------|------|------|------|
| 平均リトライ数 | 0.17 | **10.67** | **+6,176%** |
| 総不採用数 | 1 | **96** | **+9,500%** |
| thought_check不採用 | 0 | 96 | +96 |
| tone_check不採用 | 1 | 0 | -1 |

### 4.2 不採用理由の分析

**v0.4の全不採用（96件）がthought_checkによるもの：**

```
不採用理由: Thoughtが見つかりません。思考（Thought）と発言（Output）の2段階で応答してください。
問題: LLMが "Thought:" マーカーなしで応答
例: (にっこり笑って) 「おはよう！あゆ、起きてる？」→ RETRY
```

### 4.3 LLM出力パターン分析

**Director無し時のLLM出力：**
- 約60%が Thought/Output 形式で応答
- 約40%が Output のみで応答（Thoughtマーカー無し）
- 空Thought "Thought: (" も観察

**Director有り時の効果：**
- 最大3回のリトライで Thought/Output 形式を強制
- max_retries到達後は最後の応答を採用（形式不正でも）

---

## 5. 発見された問題点

### 5.1 リトライ率の大幅増加

ThoughtCheckerの追加により、リトライ率が**6,176%増加**。これは：

1. **LLMの不安定性**: gemma3:12bは約40%の確率でThoughtマーカーを省略
2. **プロンプト遵守の課題**: Few-shot例があっても形式が安定しない
3. **max_retries制限**: 3回では形式正確な応答を保証できない

### 5.2 空Thought問題

Director無し時の観察：
```
Thought: (
Output: *くしゃくしゃと笑って* 「またそんな改まった話し方しなくてもいいって言ってるでしょ」
```

ThoughtCheckerは空Thoughtも検出するが、**max_retries到達後は通過してしまう**。

### 5.3 品質への影響

| 観点 | 評価 |
|------|------|
| 形式遵守 | ✅ 改善（リトライで矯正） |
| 思考の可視化 | △ 一部空Thoughtが通過 |
| 処理時間 | ❌ 大幅増加（18s → 35s） |
| 品質スコア | ≒ 変化なし (0.71) |

---

## 6. 推奨アクション

### 6.1 短期対応（v0.4.1）

| 優先度 | アクション | 理由 |
|--------|-----------|------|
| 高 | **ThoughtCheckerをオプショナル化** | リトライ削減 |
| 高 | **設定フラグ追加**: `enforce_thought_format` | 柔軟な運用 |
| 中 | 空Thought許容モード検討 | 形式より内容重視 |

### 6.2 中期対応

| 優先度 | アクション | 理由 |
|--------|-----------|------|
| 高 | プロンプト改善（Thought形式強化） | LLM遵守率向上 |
| 中 | Few-shot例の増強 | 形式定着 |
| 低 | max_retries増加検討 | 形式保証率向上 |

### 6.3 推奨構成

**本番環境推奨（v0.4.1）:**
```python
director = DirectorMinimal(
    enforce_thought_format=False  # ThoughtChecker無効化
)
# → v0.3相当のリトライ率を維持
```

**品質重視環境:**
```python
director = DirectorMinimal(
    enforce_thought_format=True,  # ThoughtChecker有効
    max_retries=5                 # リトライ上限増加
)
# → 形式遵守を強制
```

---

## 7. 結論

### v0.4の評価

| 項目 | 結果 |
|------|------|
| ThoughtChecker機能 | ✅ 正常動作 |
| 形式検出 | ✅ 全件検出 |
| リトライ率 | ❌ 大幅増加 |
| 品質改善 | △ 有意差なし |

### 結論

ThoughtChecker (v0.4) は**技術的には正常動作**しているが、**運用上の課題**が大きい：

1. **リトライコスト**: 10.67回/セッションは許容範囲外
2. **品質効果**: スコア改善効果は観察されず
3. **LLM依存**: gemma3:12bのThought形式遵守率が低い

**推奨**: ThoughtCheckerは**オプショナル機能**として提供し、デフォルトは無効化。
Thought形式が重要なユースケース（デバッグ、分析）でのみ有効化する。

---

## 8. 会話サンプル（抜粋）

### 不採用応答例（thought_check）

**casual_greeting, Turn 1 (やな):**

❌ Attempt 1:
```
Response: (にっこり笑って) 「おはよう！あゆ、起きてる？ 良い天気だね～」
Status: RETRY
Reason: Thoughtが見つかりません。思考（Thought）と発言（Output）の2段階で応答してください。
```

❌ Attempt 2:
```
Response: (伸びをして) 「おはよう！あゆ、ちゃんと寝た？　今日はいいことありそうだね、ね」
Status: RETRY
Reason: Thoughtが見つかりません。
```

❌ Attempt 3:
```
Response: (にっこり笑って) 「おはよう！あゆ、ちゃんと寝れた？」
Status: RETRY
Reason: Thoughtが見つかりません。
```

✅ Adopted (max_retries到達後):
```
Response: (にっこり笑って) 「おはよう！あゆ、ちゃんと寝れた？」
```

**分析**: 3回リトライしても形式改善せず。max_retries到達で最後の応答を採用。

### 正常通過例（Director無し）

**topic_exploration, Turn 1 (やな):**
```
Thought: (Yana: あゆ、AIの話となったら目が輝くだろうな。)
Output: (目を輝かせて) 「AIの話！最近、ChatGPTとか話題になってるよね！あゆ、なんか面白い技術ある？」
```

**分析**: LLMがThought/Output形式で応答。形式遵守率は約60%。

---

*Generated by duo-talk-evaluation v0.4 analysis framework*
